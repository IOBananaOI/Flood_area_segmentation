{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h2D_saaDaWRR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "api_token = {\"username\":\"iobananaoi\",\"key\":\"0cbdda23beeb18cbb57e9e88bf26bfd1\"}\n",
        "\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import kaggle \n",
        "import torch \n",
        "import cv2\n",
        "import copy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from datetime import date\n",
        "from torch import nn\n",
        "from zipfile import ZipFile\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from torchvision.transforms import ToTensor, Compose, ToPILImage, CenterCrop\n",
        "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
        "from torch.optim import lr_scheduler\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "xBgk1H3ddc9S"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d faizalkarim/flood-area-segmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shmo7T6Jefnf",
        "outputId": "a36bc664-066d-4f5a-efb8-c6f33fab2bc7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading flood-area-segmentation.zip to /content\n",
            " 99% 106M/107M [00:03<00:00, 39.2MB/s]\n",
            "100% 107M/107M [00:03<00:00, 31.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = ZipFile(\"/content/flood-area-segmentation.zip\")\n",
        "f.extractall(\"/content/data\")"
      ],
      "metadata": {
        "id": "nB9_OSB7euTQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_rename(src, dim) -> None:\n",
        "    files = [f for f in listdir(src) if isfile(join(src, f))]\n",
        "    for i, name in enumerate(files):  \n",
        "\n",
        "        name = src+name\n",
        "        new_name = src + f\"{i}.{dim}\"\n",
        "        print(new_name)\n",
        "\n",
        "        os.rename(name, new_name)"
      ],
      "metadata": {
        "id": "inhAcjKSfmi9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 15\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "HGwRsc1Logn3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d0534184-8bb8-4a3a-c570-4980f20c36d0"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meta = pd.read_csv(\"/content/data/metadata.csv\")\n",
        "meta.drop(index=[0,2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hKKMyBxqm06W",
        "outputId": "9e9232af-708f-44b1-dd30-62797879bdda"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Image      Mask\n",
              "1       1.jpg     1.png\n",
              "3       3.jpg     3.png\n",
              "4       4.jpg     4.png\n",
              "5       5.jpg     5.png\n",
              "6       6.jpg     6.png\n",
              "..        ...       ...\n",
              "285  1083.jpg  1083.png\n",
              "286  1084.jpg  1084.png\n",
              "287  1085.jpg  1085.png\n",
              "288  1086.jpg  1086.png\n",
              "289  1087.jpg  1087.png\n",
              "\n",
              "[288 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-930e9f2d-fb40-4be2-8beb-82be119fc07e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>1.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>3.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>4.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.jpg</td>\n",
              "      <td>5.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.jpg</td>\n",
              "      <td>6.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>1083.jpg</td>\n",
              "      <td>1083.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>1084.jpg</td>\n",
              "      <td>1084.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>1085.jpg</td>\n",
              "      <td>1085.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>1086.jpg</td>\n",
              "      <td>1086.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>1087.jpg</td>\n",
              "      <td>1087.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>288 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-930e9f2d-fb40-4be2-8beb-82be119fc07e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-930e9f2d-fb40-4be2-8beb-82be119fc07e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-930e9f2d-fb40-4be2-8beb-82be119fc07e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "vJGWHZuZeHbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DS(Dataset):\n",
        "    def __init__(self, transform):\n",
        "        self.transform = transform\n",
        "        self.meta = pd.read_csv(\"/content/data/metadata.csv\")\n",
        "        self.meta.drop(index=[0,2, 151], inplace=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(\"/content/data/Image/\"+self.meta.iloc[idx][\"Image\"])\n",
        "        label = Image.open(\"/content/data/Mask/\"+self.meta.iloc[idx][\"Mask\"])\n",
        "        \n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "            label = self.transform(label)\n",
        "        \n",
        "        return img, label"
      ],
      "metadata": {
        "id": "uJpBoSHVdfzY"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = DS(Compose([CenterCrop(304), ToTensor()]))"
      ],
      "metadata": {
        "id": "jLplb8w0nPkE"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(ds, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "I5clvoj8oALS"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_num = len(ds) // batch_size"
      ],
      "metadata": {
        "id": "fvWALhc26qrg"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model structure"
      ],
      "metadata": {
        "id": "2Yx9gdA11Unq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consider various model structures such as U-Net and DEEPLABV3 and then compare the results"
      ],
      "metadata": {
        "id": "P6grnYuc1WaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u_net = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk6otYMFqGDe",
        "outputId": "fe77d5d8-4e46-44d7-ae38-f4d9b9bc54e3"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "bjR6NW0EkcrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, loss_fn, optim, scheduler, epochs=epochs):\n",
        "    model.train()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 10000\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"======= Epoch {epoch+1} =======\")\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            if batch < batch_num:\n",
        "                optim.zero_grad()\n",
        "                pred = model(X)\n",
        "                loss = loss_fn(pred, y)\n",
        "\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "        running_loss /= batch_num\n",
        "        losses.append(running_loss)\n",
        "        print(f\"Loss: {running_loss:.4f}\")\n",
        "\n",
        "        if running_loss < best_loss:\n",
        "            best_loss = running_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "    model.load_state_dict(best_model_wts)   \n",
        "\n",
        "    print(f\"Model state saved with the best loss: {best_loss:.4f}\")\n",
        "\n",
        "    return losses     "
      ],
      "metadata": {
        "id": "BN_XV8ynpAk0"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## U_net"
      ],
      "metadata": {
        "id": "45PCkS4yqcI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = u_net.to(device)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = lr_scheduler.StepLR(optim, step_size=2, gamma=0.1)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "4tPy12b64Z4B"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Rj9QmDrfKfJV"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = train(model, dl, loss_fn, optim, scheduler, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjM1g2sbCoFs",
        "outputId": "dc398333-2ec9-41af-d333-ca57d0499400"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Epoch 1 =======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/PIL/TiffImagePlugin.py:767: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 19. Skipping tag 36867\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.8741\n",
            "======= Epoch 2 =======\n",
            "Loss: 0.7805\n",
            "======= Epoch 3 =======\n",
            "Loss: 0.5822\n",
            "======= Epoch 4 =======\n",
            "Loss: 0.5596\n",
            "======= Epoch 5 =======\n",
            "Loss: 0.5081\n",
            "======= Epoch 6 =======\n",
            "Loss: 0.4753\n",
            "======= Epoch 7 =======\n",
            "Loss: 0.4502\n",
            "======= Epoch 8 =======\n",
            "Loss: 0.4475\n",
            "======= Epoch 9 =======\n",
            "Loss: 0.4308\n",
            "======= Epoch 10 =======\n",
            "Loss: 0.4194\n",
            "======= Epoch 11 =======\n",
            "Loss: 0.3919\n",
            "======= Epoch 12 =======\n",
            "Loss: 0.4134\n",
            "======= Epoch 13 =======\n",
            "Loss: 0.4053\n",
            "======= Epoch 14 =======\n",
            "Loss: 0.4134\n",
            "======= Epoch 15 =======\n",
            "Loss: 0.3788\n",
            "Model state saved with the best loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deeplabv3"
      ],
      "metadata": {
        "id": "Tm61zVQPqha8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deeplabv3 = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClccXz5vqjmg",
        "outputId": "de27b8b9-10ee-45cc-c994-37aa4fa6105f"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = deeplabv3.to(device)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = lr_scheduler.StepLR(optim, step_size=2, gamma=0.1)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "DOm35B-mqvxs"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "DawWGfn_qghn"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = to_tensor(Image.open(\"/content/data/Image/1000.jpg\")).to(device)"
      ],
      "metadata": {
        "id": "dnFocFkLupVj"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(losses, range(epochs))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "xQCmIENVDArj",
        "outputId": "6bcab6a1-88d0-4aac-ca32-e8af8b06a053"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results comparing"
      ],
      "metadata": {
        "id": "fw4n3Zdi0yKi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ulHdtmCgp0vQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}